alpha <- 0.025
umbral2 <- qchisq(1 - alpha, df = p) # sobre D^2
umbral  <- sqrt(umbral2)             # sobre D (md.rob)
plot(distances_df$md.rob,
type = "h",
ylab = "Distancia de Mahalanobis robusta",
xlab = "Índice de observación",
main = sprintf("Outliers multivariantes (p=%d)", p))
abline(h = umbral, col = "red", lwd = 2, lty = 2)
distancia_mahalanobis <- mahalanobis(datos[,varNum], colMeans(datos[,varNum]), cov(datos[,varNum]))
summary(distancia_mahalanobis)
library(adamethods)
res_knn<-do_knno(datos[,varNum], k=1, top_n=3000)
## --- Parámetros ---
k <- 1              # usa el mismo k que en do_knno()
idx_targets <- res_knn  # tus 100 índices
## --- 1) Preparar matriz X con variables numéricas ---
X <- datos[, varNum, drop = FALSE]
p <- ncol(X)
## --- 2) Estandarizar por columna ignorando NAs ---
std_col <- function(v) {
mu <- mean(v, na.rm = TRUE)
sdv <- sd(v, na.rm = TRUE)
if (is.na(sdv) || sdv == 0) return((v - mu))   # evita dividir por 0
(v - mu) / sdv
}
Xs <- as.data.frame(lapply(X, std_col))
Xs <- as.matrix(Xs)  # para operaciones más rápidas
n <- nrow(Xs)
## --- 3) Función de distancia euclídea "pairwise" ajustada por missingness ---
## d_ij = sqrt( sum((xi-xj)^2 over m) * (p / m) ), con m vars observadas en el par
pairwise_dist_row <- function(i, Xs) {
xi <- Xs[i, ]
# Máscara NA por columnas respecto xi (TRUE si xi es no-NA)
mask_i <- !is.na(xi)
d <- rep(NA_real_, n)
for (j in 1:n) {
if (j == i) next
xj <- Xs[j, ]
mask <- mask_i & !is.na(xj)
m <- sum(mask)
if (m == 0) {
d[j] <- NA_real_
} else {
diff2 <- xi[mask] - xj[mask]
d[j] <- sqrt(sum(diff2 * diff2) * (p / m))
}
}
d
}
## --- 4) Obtener el k-NN distance para cada índice objetivo respecto a TODO el dataset ---
get_knn_dist <- function(i, Xs, k = 1) {
d <- pairwise_dist_row(i, Xs)
# Ordenar ignorando NAs y excluyendo la propia observación
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
vec[k]
}
## --- 5) Calcular scores para tus 100 observaciones ---
scores_res <- vapply(idx_targets, function(i) get_knn_dist(i, Xs, k = k), numeric(1))
resultado_res_knn <- data.frame(
fila = idx_targets,
score_knn = scores_res
)
## --- (Opcional) Si quieres una versión 'avg_k' (media de las k distancias más cercanas) ---
get_knn_avgdist <- function(i, Xs, k = 5) {
d <- pairwise_dist_row(i, Xs)
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
mean(vec[1:k])
}
# ejemplo: avg_scores_res <- vapply(idx_targets, function(i) get_knn_avgdist(i, Xs, k = 5), numeric(1))
## --- (Opcional) Normalizaciones monótonas para alinear la "escala" de do_knno ---
## Mantienen el ranking, por si do_knno aplica alguna de estas:
minv <- min(scores_res, na.rm = TRUE); maxv <- max(scores_res, na.rm = TRUE)
resultado_res_knn$score_minmax_0_1 <- (resultado_res_knn$score_knn - minv) / (maxv - minv)
medv <- median(scores_res, na.rm = TRUE); madv <- mad(scores_res, constant = 1, na.rm = TRUE)
resultado_res_knn$score_robust_z <- (resultado_res_knn$score_knn - medv) / madv
## --- Ordenar por mayor sospecha (score más grande) ---
resultado_res_knn <- resultado_res_knn[order(-resultado_res_knn$score_knn), ]
## Ver top
head(resultado_res_knn, 10)
plot(resultado_res_knn$score_robust_z)
abline(h=3)
outliers <- resultado_res_knn$fila[resultado_res_knn$score_robust_z > 3]
length(outliers)
length(outliers)/13186
datos<-datos[-outliers,]
library(mice)
tempData <- mice(datos,m=5,maxit=50,meth='pmm',seed=500)
library(caret)
# install.packages("idealista18")
require(idealista18)
library(tidyverse)
numeric_cols <- sapply(datos, is.numeric)
datos_num <- datos[, numeric_cols]
# ncol(datos_num); ncol(datos)
varianza <- nearZeroVar(datos_num, saveMetrics = T)
varianza
datos_cor <- cor(na.omit(datos_num))
(alta_cor <- findCorrelation(datos_cor, cutoff = 0.6))
library("corrplot")
matriz_corr <- cor(datos_cor)
corrplot(matriz_corr, method = "circle")
datos_num_na <- tidyr::drop_na(datos_num) # Es necesario eliminar los NA.
(combos <- findLinearCombos(datos_num_na[,-c(1,13)]))
#################################################################
### TODAS LAS VARIABLES DEBEN SER CATEGÓRICAS O LÓGICAS
### Si son numéricas, se discretizan (por ejemplo, en 3 niveles)
#################################################################
for (j in 1:ncol(datos_prepro)) {
if (is.numeric(datos_prepro[, j])) {
datos_prepro[, j] <- cut(datos_prepro[, j],
breaks = 3,
labels = c("Low", "Medium", "High"))
}
}
# Verificamos que todo sea factor o lógico
str(datos_prepro)
summary(datos_prepro)
#################################################################
### TRANSFORMACIÓN DE 'datos_prepro' EN BASE TRANSACCIONAL
#################################################################
library(arules)
library(tidyverse)
# 1 Asegurar que todas las variables son factores o lógicas
datos_prepro2 <- datos_prepro
for (j in 1:ncol(datos_prepro2)) {
# Si es numérica, discretizamos en 3 niveles
if (is.numeric(datos_prepro2[, j])) {
datos_prepro2[, j] <- cut(datos_prepro2[, j],
breaks = 3,
labels = c("Low", "Medium", "High"))
}
# Convertimos todo a factor explícitamente
datos_prepro2[, j] <- as.factor(datos_prepro2[, j])
}
# Confirmamos la estructura
str(datos_prepro2)
summary(datos_prepro2)
# Transformamos a transacciones
datos_trans <- as(datos_prepro2, "transactions")
# Revisamos el resultado
datos_trans
summary(datos_trans)
inspect(head(datos_trans, 5))
transactionInfo(datos_trans[1:10])
# Cantidad de transacciones e ítems
datos_trans
summary(datos_trans)
class(datos_trans)
# FUNCTION inspect
inspect(datos_trans[1:6])
transactionInfo(datos_trans[1:10])
# Distribución del tamaño de transacciones
SIZE <- size(datos_trans)
summary(SIZE)
quantile(SIZE, probs = seq(0,1,0.1))
#################################################################
### FRECUENCIA DE ÍTEMS
#################################################################
itemFrequency(datos_trans)
itemFrequencyPlot(datos_trans, topN=5, cex.names=0.5) ## Los 5 ítems más comunes
## y su frecuencia
itemFrequencyPlot(datos_trans, cex.names=0.4) ## Grráfico de frecuencias de
## todos los ítems
itemFrequencyPlot(datos_trans, support=0.01, cex.names=0.5) ## Gráfico de
## frecuencias de todos los ítems con una frecuencia superior a 0.01
itemFrequencyPlot(datos_trans, type="absolute", cex.names=0.3)
itemFrequencyPlot(datos_trans, topN=20, type="absolute", cex.names=0.6)
frequency_items <- itemFrequency(x = datos_trans, type = "relative")
frequency_items %>% sort(decreasing = TRUE) %>% head(5)
frequency_items <- itemFrequency(x = datos_trans, type = "relative")
frequency_items %>% sort(decreasing = TRUE) %>% head(35)
#################################################################
### EXTRACCIÓN DE CONJUNTOS FRECUENTES (FREQUENT ITEMSETS)
#################################################################
itemsets <- apriori(data = datos_trans,
parameter = list(support = 0.05,
minlen = 1,
maxlen = 5,
target = "frequent itemset"))
summary(itemsets)
inspect(itemsets[1:5])
summary(itemsets)
top_20_itemsets <- sort(itemsets, by = "support", decreasing = TRUE)[1:20]
inspect(top_20_itemsets)
inspect(sort(itemsets[size(itemsets) > 1], decreasing = TRUE)[1:20])
itemsets <- apriori(data = datos_trans,
parameter = list(support = 0.05,
minlen = 2,
maxlen = 5,
target = "frequent itemset"))
summary(itemsets)
summary(cat)
# Configurar opciones para mejor visualización
options(digits = 3)
# Verificar estructura de los datos
cat("=== ESTRUCTURA INICIAL DE LOS DATOS ===\n")
str(datos_prepro)
summary(datos_prepro)
# Convertir variables lógicas a factores (si aplica)
cat("\n=== CONVERSIÓN DE VARIABLES ===\n")
for (j in 1:ncol(datos_prepro)) {
if(class(datos_prepro[,j]) == "logical") {
datos_prepro[,j] <- as.factor(datos_prepro[,j])
cat("Convertida columna", j, names(datos_prepro)[j], "de logical a factor\n")
}
}
# Verificar estructura final
cat("\n=== ESTRUCTURA FINAL ===\n")
str(datos_prepro)
cat("=== CONVERSIÓN A TRANSACCIONES ===\n")
# Método robusto de conversión
tryCatch({
datos_transacciones <- as(datos_prepro, "transactions")
}, error = function(e) {
cat("Error en conversión directa, usando método alternativo...\n")
# Convertir todas las columnas a factores primero
datos_prepro_factors <- as.data.frame(lapply(datos_prepro, as.factor))
datos_transacciones <- as(datos_prepro_factors, "transactions")
})
# Resumen de las transacciones
cat("\n=== RESUMEN DE TRANSACCIONES ===\n")
summary(datos_transacciones)
# Visualizar items más frecuentes
itemFrequencyPlot(datos_transacciones,
topN = 15,
main = "15 Características Musicales Más Frecuentes",
col = "steelblue",
type = "relative")
# Cantidad de transacciones e ítems
datos_trans
summary(datos_trans)
class(datos_trans)
# FUNCTION inspect
inspect(datos_trans[1:6])
transactionInfo(datos_trans[1:10])
# Distribución del tamaño de transacciones
SIZE <- size(datos_trans)
summary(SIZE)
quantile(SIZE, probs = seq(0,1,0.1))
cat("=== ITEMSETS FRECUENTES ===\n")
# Encontrar itemsets frecuentes
itemsets_frecuentes <- apriori(datos_transacciones,
parameter = list(support = 0.05,
minlen = 2,
maxlen = 4,
target = "frequent itemsets"))
cat("Número de itemsets frecuentes encontrados:", length(itemsets_frecuentes), "\n")
# Mostrar los 10 itemsets más frecuentes
cat("\n=== TOP 10 ITEMSETS POR SUPPORT ===\n")
inspect(sort(itemsets_frecuentes, by = "support")[1:10])
inspect(sort(itemsets_frecuentes, by = "support")[1:10])
cat("=== ITEMSETS FRECUENTES ===\n")
# Encontrar itemsets frecuentes
itemsets_frecuentes <- apriori(datos_transacciones,
parameter = list(support = 0.05,
minlen = 2,
maxlen = 4,
target = "frequent itemsets"))
cat("Número de itemsets frecuentes encontrados:", length(itemsets_frecuentes), "\n")
# Mostrar los 10 itemsets más frecuentes
cat("\n=== TOP 10 ITEMSETS POR SUPPORT ===\n")
inspect(sort(itemsets_frecuentes, by = "support")[1:10])
inspect(sort(itemsets_frecuentes, by = "support")[1:10])
inspect(sort(itemsets_frecuentes, by = "support")[1:10])
cat("=== ITEMSETS FRECUENTES ===\n")
# Probar con diferentes valores de support
supports <- c(0.01, 0.02, 0.03, 0.05)
itemsets_encontrados <- FALSE
for (sup in supports) {
itemsets_frecuentes <- apriori(datos_transacciones,
parameter = list(support = sup,
minlen = 2,
maxlen = 3,  # Reducir longitud máxima
target = "frequent itemsets"))
cat("Support =", sup, "-> Itemsets encontrados:", length(itemsets_frecuentes), "\n")
if (length(itemsets_frecuentes) > 0) {
itemsets_encontrados <- TRUE
break
}
}
if (itemsets_encontrados) {
cat("\n=== TOP ITEMSETS POR SUPPORT ===\n")
# Mostrar todos los itemsets encontrados (hasta 10)
n_mostrar <- min(10, length(itemsets_frecuentes))
inspect(sort(itemsets_frecuentes, by = "support")[1:n_mostrar])
} else {
cat("\n*** No se encontraron itemsets frecuentes. Probando con parámetros más flexibles... ***\n")
# Intentar con parámetros más flexibles
itemsets_frecuentes <- apriori(datos_transacciones,
parameter = list(support = 0.005,  # Más bajo
minlen = 1,        # Permitir itemsets de 1
maxlen = 2,
target = "frequent itemsets"))
cat("Con support = 0.005 -> Itemsets encontrados:", length(itemsets_frecuentes), "\n")
if (length(itemsets_frecuentes) > 0) {
n_mostrar <- min(10, length(itemsets_frecuentes))
inspect(sort(itemsets_frecuentes, by = "support")[1:n_mostrar])
} else {
cat("*** No se pudieron encontrar itemsets frecuentes con los parámetros actuales ***\n")
cat("*** Revisar la estructura de los datos transaccionales ***\n")
print(summary(datos_transacciones))
}
}
#################################################################
### FRECUENCIA DE ÍTEMS
#################################################################
itemFrequency(datos_trans)
itemFrequencyPlot(datos_trans, topN=5, cex.names=0.5) ## Los 5 ítems más comunes
## y su frecuencia
itemFrequencyPlot(datos_trans, cex.names=0.4) ## Grráfico de frecuencias de
## todos los ítems
itemFrequencyPlot(datos_trans, support=0.01, cex.names=0.5) ## Gráfico de
## frecuencias de todos los ítems con una frecuencia superior a 0.01
itemFrequencyPlot(datos_trans, type="absolute", cex.names=0.3)
itemFrequencyPlot(datos_trans, topN=20, type="absolute", cex.names=0.6)
frequency_items <- itemFrequency(x = datos_trans, type = "relative")
frequency_items %>% sort(decreasing = TRUE) %>% head(5)
cat("=== GENERACIÓN DE REGLAS DE ASOCIACIÓN ===\n")
# Probar diferentes combinaciones de parámetros
parametros_list <- list(
list(support = 0.01, confidence = 0.3),
list(support = 0.005, confidence = 0.2),
list(support = 0.02, confidence = 0.4)
)
reglas_encontradas <- FALSE
for (params in parametros_list) {
reglas <- apriori(datos_transacciones,
parameter = list(support = params[[1]],
confidence = params[[2]],
minlen = 1,  # Permitir reglas más simples
maxlen = 3))
cat("Support =", params[[1]], "Confidence =", params[[2]],
"-> Reglas encontradas:", length(reglas), "\n")
if (length(reglas) > 0) {
reglas_encontradas <- TRUE
break
}
}
if (reglas_encontradas) {
cat("Total de reglas generadas:", length(reglas), "\n")
# Filtrar reglas interesantes (parámetros más flexibles)
if (length(reglas) > 0) {
calidad_reglas <- quality(reglas)
reglas_interesantes <- reglas[
calidad_reglas$lift > 1.0 &  # Más flexible
calidad_reglas$confidence > 0.3  # Más flexible
]
cat("Reglas interesantes (lift > 1.0, confidence > 0.3):", length(reglas_interesantes), "\n")
if (length(reglas_interesantes) > 0) {
# Ordenar y mostrar
reglas_ordenadas <- sort(reglas_interesantes, by = "lift", decreasing = TRUE)
n_mostrar <- min(15, length(reglas_ordenadas))
cat("\n=== TOP", n_mostrar, "REGLAS POR LIFT ===\n")
inspect(reglas_ordenadas[1:n_mostrar])
}
}
} else {
cat("*** No se pudieron generar reglas con los parámetros estándar ***\n")
reglas_interesantes <- reglas  # Vacío pero evita error
}
cat("=== ANÁLISIS ESPECÍFICO DE POPULARIDAD ===\n")
# Verificar si existe la variable de popularidad
labels_transacciones <- itemLabels(datos_transacciones)
cat("Variables disponibles en las transacciones:\n")
print(labels_transacciones)
# Buscar patrones relacionados con popularidad
patrones_popularidad <- grep("popular", labels_transacciones, ignore.case = TRUE, value = TRUE)
if (length(patrones_popularidad) > 0) {
cat("Variables de popularidad encontradas:", patrones_popularidad, "\n")
reglas_popularidad <- list()
for (patron in patrones_popularidad) {
cat("\nBuscando reglas para:", patron, "\n")
# Reglas que predicen popularidad
reglas_rhs <- tryCatch({
apriori(datos_transacciones,
parameter = list(support = 0.005, confidence = 0.2, minlen = 2),
appearance = list(rhs = patron, default = "lhs"))
}, error = function(e) NULL)
if (!is.null(reglas_rhs) && length(reglas_rhs) > 0) {
cat("Reglas encontradas para", patron, "en RHS:", length(reglas_rhs), "\n")
reglas_popularidad <- c(reglas_popularidad, reglas_rhs)
}
}
if (length(reglas_popularidad) > 0) {
reglas_popularidad <- do.call(c, reglas_popularidad)
reglas_popularidad <- sort(reglas_popularidad, by = "lift")
cat("Total de reglas de popularidad:", length(reglas_popularidad), "\n")
} else {
cat("No se encontraron reglas específicas de popularidad\n")
reglas_popularidad <- reglas_interesantes
}
} else {
cat("No se encontraron variables específicas de popularidad\n")
cat("Analizando todas las reglas disponibles...\n")
reglas_popularidad <- reglas_interesantes
}
cat("=== ANÁLISIS SIMPLIFICADO DE POPULARIDAD ===\n")
# Enfoque directo - solo las mejores reglas
labels_transacciones <- itemLabels(datos_transacciones)
patron_popularidad <- grep("popular", labels_transacciones, ignore.case = TRUE, value = TRUE)[1]
if (!is.na(patron_popularidad)) {
cat("Analizando variable:", patron_popularidad, "\n")
# Solo generar reglas muy específicas y de alta calidad
reglas_popularidad <- tryCatch({
reglas <- apriori(datos_transacciones,
parameter = list(
support = 0.03,     # Solo patrones comunes
confidence = 0.7,   # Solo muy confiables
minlen = 2,
maxlen = 3
),
appearance = list(rhs = patron_popularidad, default = "lhs"))
# Filtrar y limitar
reglas_filtradas <- reglas[quality(reglas)$lift > 1.5]
head(sort(reglas_filtradas, by = "lift", decreasing = TRUE), 10)  # TOP 10
}, error = function(e) {
cat("No se pudieron generar reglas específicas\n")
return(reglas_interesantes)
})
} else {
reglas_popularidad <- head(reglas_interesantes, 10)  # Solo 10 mejores generales
}
cat("Reglas finales para análisis:", length(reglas_popularidad), "\n")
if (length(reglas_popularidad) > 0) {
cat("\n=== REGLAS DE POPULARIDAD ===\n")
inspect(reglas_popularidad)
}
cat("=== EVALUACIÓN DE REGLAS ===\n")
# Mostrar las mejores reglas
cat("\n=== MEJORES REGLAS POR LIFT ===\n")
mejores_reglas <- head(sort(reglas_popularidad, by = "lift", decreasing = TRUE), 15)
inspect(mejores_reglas)
# Métricas de calidad
cat("\n=== MÉTRICAS DE CALIDAD ===\n")
calidad <- quality(mejores_reglas)
print(summary(calidad))
# Visualizaciones
cat("\n=== CREANDO VISUALIZACIONES ===\n")
# Scatter plot de las reglas
plot(mejores_reglas,
method = "scatter",
main = "Distribución de Reglas - Support vs Confidence")
install.packages("arulesViz")
cat("=== EVALUACIÓN DE REGLAS ===\n")
# Mostrar las mejores reglas
cat("\n=== MEJORES REGLAS POR LIFT ===\n")
mejores_reglas <- head(sort(reglas_popularidad, by = "lift", decreasing = TRUE), 15)
inspect(mejores_reglas)
# Métricas de calidad
cat("\n=== MÉTRICAS DE CALIDAD ===\n")
calidad <- quality(mejores_reglas)
print(summary(calidad))
# Visualizaciones
cat("\n=== CREANDO VISUALIZACIONES ===\n")
# Scatter plot de las reglas
plot(mejores_reglas,
method = "scatter",
main = "Distribución de Reglas - Support vs Confidence")
library(arulesViz)
cat("=== EVALUACIÓN DE REGLAS ===\n")
# Mostrar las mejores reglas
cat("\n=== MEJORES REGLAS POR LIFT ===\n")
mejores_reglas <- head(sort(reglas_popularidad, by = "lift", decreasing = TRUE), 15)
inspect(mejores_reglas)
# Métricas de calidad
cat("\n=== MÉTRICAS DE CALIDAD ===\n")
calidad <- quality(mejores_reglas)
print(summary(calidad))
# Visualizaciones
cat("\n=== CREANDO VISUALIZACIONES ===\n")
# Scatter plot de las reglas
plot(mejores_reglas,
method = "scatter",
main = "Distribución de Reglas - Support vs Confidence")
# Gráfico de matriz
plot(mejores_reglas,
method = "matrix",
main = "Matriz de Reglas")
# Gráfico interactivo (si está disponible)
tryCatch({
plot(mejores_reglas,
method = "graph",
main = "Grafo de Reglas de Asociación")
}, error = function(e) {
cat("Gráfico interactivo no disponible\n")
})
cat("=== EXPORTACIÓN DE RESULTADOS ===\n")
# Crear dataframe con las reglas
resultados_df <- as(mejores_reglas, "data.frame")
# Exportar a CSV
write.csv(resultados_df, "reglas_asociacion_musica.csv", row.names = FALSE)
cat("Resultados exportados a 'reglas_asociacion_musica.csv'\n")
# Mostrar resumen ejecutivo
cat("\n=== RESUMEN EJECUTIVO ===\n")
cat("Total reglas generadas:", length(reglas), "\n")
cat("Reglas filtradas interesantes:", length(reglas_interesantes), "\n")
cat("Mejores reglas identificadas:", length(mejores_reglas), "\n")
cat("Lift máximo:", max(quality(mejores_reglas)$lift), "\n")
cat("Confidence máximo:", max(quality(mejores_reglas)$confidence), "\n")
cat("=== INTERPRETACIÓN ===\n")
cat("Las reglas muestran patrones entre características musicales y popularidad.\n")
cat("Lift > 1 indica asociación positiva significativa.\n")
cat("Confidence > 0.6 indica reglas confiables.\n")
cat("Support indica la frecuencia del patrón en los datos.\n")
cat("=== INTERPRETACIÓN ===\n")
cat("Las reglas muestran patrones entre características musicales y popularidad.\n")
cat("Lift > 1 indica asociación positiva significativa.\n")
cat("Confidence > 0.6 indica reglas confiables.\n")
cat("Support indica la frecuencia del patrón en las transacciones.\n")
