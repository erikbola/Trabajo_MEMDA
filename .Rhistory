res[is.na(x)] <- FALSE  # los NA originales no cuentan como outliers
return(res)
}
# Aplicar a cada variable (columna)
outlier_matrix <- as.data.frame(lapply(X, is_outlier, method = "iqr"))
# ¿Cuántos outliers por variable?
outlier_counts <- colSums(outlier_matrix)
outlier_vars <- names(outlier_counts[outlier_counts > 0])
cat("Variables con outliers detectados:\n")
print(outlier_vars)
# --- Crear resumen por observación ---
outlier_summary <- data.frame(
obs = 1:nrow(X),
n_outlier_vars = rowSums(outlier_matrix),
vars_outlier = apply(outlier_matrix, 1, function(row) {
paste(names(X)[which(row)], collapse = ", ")
})
)
# Mostrar observaciones con al menos un outlier
outlier_summary_nonzero <- subset(outlier_summary, n_outlier_vars > 0)
head(outlier_summary_nonzero, 10)
# --- (Opcional) Reemplazar los outliers por NA en X ---
X_no_outliers <- X
for (v in names(X)) {
X_no_outliers[outlier_matrix[[v]], v] <- NA
}
## --- Parámetros ---
k <- 1              # usa el mismo k que en do_knno()
idx_targets <- res_knn  # tus 100 índices
## --- 1) Preparar matriz X con variables numéricas ---
X <- datos[, varNum, drop = FALSE]
p <- ncol(X)
## --- 2) Estandarizar por columna ignorando NAs ---
std_col <- function(v) {
mu <- mean(v, na.rm = TRUE)
sdv <- sd(v, na.rm = TRUE)
if (is.na(sdv) || sdv == 0) return((v - mu))   # evita dividir por 0
(v - mu) / sdv
}
Xs <- as.data.frame(lapply(X, std_col))
Xs <- as.matrix(Xs)  # para operaciones más rápidas
n <- nrow(Xs)
## --- 2b) Identificar variables con outliers ---
# Función auxiliar: detecta outliers por variable numérica
detect_outliers <- function(x, method = c("zscore", "iqr"), threshold = 3) {
method <- match.arg(method)
x_noNA <- x[!is.na(x)]
if (method == "zscore") {
z <- (x_noNA - mean(x_noNA)) / sd(x_noNA)
outliers <- which(abs(z) > threshold)
} else if (method == "iqr") {
q1 <- quantile(x_noNA, 0.25)
q3 <- quantile(x_noNA, 0.75)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
outliers <- which(x_noNA < lower | x_noNA > upper)
}
return(length(outliers))
}
# Aplicar a cada variable numérica
outlier_counts <- sapply(X, detect_outliers, method = "iqr")  # puedes cambiar "iqr" por "zscore"
outlier_vars <- names(outlier_counts[outlier_counts > 0])
## Resumen
cat("Variables con outliers detectados:\n")
print(outlier_vars)
cat("\nNúmero de outliers por variable:\n")
print(outlier_counts[outlier_counts > 0])
## (Opcional) Crear un data.frame resumen
resumen_outliers <- data.frame(
variable = names(outlier_counts),
n_outliers = outlier_counts,
prop_outliers = outlier_counts / nrow(X)
)
# Ver las más afectadas
head(resumen_outliers[order(-resumen_outliers$n_outliers), ])
## --- 2c) Identificar y marcar outliers por observación y variable ---
# Función que devuelve un vector lógico (TRUE si es outlier)
is_outlier <- function(x, method = c("zscore", "iqr"), threshold = 3) {
method <- match.arg(method)
res <- rep(FALSE, length(x))
if (method == "zscore") {
z <- (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
res <- abs(z) > threshold
} else if (method == "iqr") {
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
res <- x < lower | x > upper
}
res[is.na(x)] <- FALSE  # los NA originales no cuentan como outliers
return(res)
}
# Aplicar a cada variable (columna)
outlier_matrix <- as.data.frame(lapply(X, is_outlier, method = "iqr"))
# ¿Cuántos outliers por variable?
outlier_counts <- colSums(outlier_matrix)
outlier_vars <- names(outlier_counts[outlier_counts > 0])
cat("Variables con outliers detectados:\n")
print(outlier_vars)
# --- Crear resumen por observación ---
outlier_summary <- data.frame(
obs = 1:nrow(X),
n_outlier_vars = rowSums(outlier_matrix),
vars_outlier = apply(outlier_matrix, 1, function(row) {
paste(names(X)[which(row)], collapse = ", ")
})
)
# Mostrar observaciones con al menos un outlier
outlier_summary_nonzero <- subset(outlier_summary, n_outlier_vars > 0)
head(outlier_summary_nonzero, 10)
# --- (Opcional) Reemplazar los outliers por NA en X ---
X_no_outliers <- X
for (v in names(X)) {
X_no_outliers[outlier_matrix[[v]], v] <- NA
}
# Si luego quieres usar la versión sin outliers:
#   -> sustituye X por X_no_outliers en los pasos siguientes
## --- 3) Función de distancia euclídea "pairwise" ajustada por missingness ---
## d_ij = sqrt( sum((xi-xj)^2 over m) * (p / m) ), con m vars observadas en el par
pairwise_dist_row <- function(i, Xs) {
xi <- Xs[i, ]
# Máscara NA por columnas respecto xi (TRUE si xi es no-NA)
mask_i <- !is.na(xi)
d <- rep(NA_real_, n)
for (j in 1:n) {
if (j == i) next
xj <- Xs[j, ]
mask <- mask_i & !is.na(xj)
m <- sum(mask)
if (m == 0) {
d[j] <- NA_real_
} else {
diff2 <- xi[mask] - xj[mask]
d[j] <- sqrt(sum(diff2 * diff2) * (p / m))
}
}
d
}
## --- 4) Obtener el k-NN distance para cada índice objetivo respecto a TODO el dataset ---
get_knn_dist <- function(i, Xs, k = 1) {
d <- pairwise_dist_row(i, Xs)
# Ordenar ignorando NAs y excluyendo la propia observación
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
vec[k]
}
## --- 5) Calcular scores para tus 100 observaciones ---
scores_res <- vapply(idx_targets, function(i) get_knn_dist(i, Xs, k = k), numeric(1))
## --- Parámetros ---
k <- 1              # usa el mismo k que en do_knno()
idx_targets <- res_knn  # tus 100 índices
## --- 1) Preparar matriz X con variables numéricas ---
X <- datos[, varNum, drop = FALSE]
p <- ncol(X)
## --- 2) Estandarizar por columna ignorando NAs ---
std_col <- function(v) {
mu <- mean(v, na.rm = TRUE)
sdv <- sd(v, na.rm = TRUE)
if (is.na(sdv) || sdv == 0) return((v - mu))   # evita dividir por 0
(v - mu) / sdv
}
Xs <- as.data.frame(lapply(X, std_col))
Xs <- as.matrix(Xs)  # para operaciones más rápidas
n <- nrow(Xs)
## --- 2b) Identificar variables con outliers ---
# Función auxiliar: detecta outliers por variable numérica
detect_outliers <- function(x, method = c("zscore", "iqr"), threshold = 3) {
method <- match.arg(method)
x_noNA <- x[!is.na(x)]
if (method == "zscore") {
z <- (x_noNA - mean(x_noNA)) / sd(x_noNA)
outliers <- which(abs(z) > threshold)
} else if (method == "iqr") {
q1 <- quantile(x_noNA, 0.25)
q3 <- quantile(x_noNA, 0.75)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
outliers <- which(x_noNA < lower | x_noNA > upper)
}
return(length(outliers))
}
# Aplicar a cada variable numérica
outlier_counts <- sapply(X, detect_outliers, method = "iqr")  # puedes cambiar "iqr" por "zscore"
outlier_vars <- names(outlier_counts[outlier_counts > 0])
## Resumen
cat("Variables con outliers detectados:\n")
print(outlier_vars)
cat("\nNúmero de outliers por variable:\n")
print(outlier_counts[outlier_counts > 0])
## (Opcional) Crear un data.frame resumen
resumen_outliers <- data.frame(
variable = names(outlier_counts),
n_outliers = outlier_counts,
prop_outliers = outlier_counts / nrow(X)
)
# Ver las más afectadas
head(resumen_outliers[order(-resumen_outliers$n_outliers), ])
## --- 2c) Identificar y marcar outliers por observación y variable ---
# Función que devuelve un vector lógico (TRUE si es outlier)
is_outlier <- function(x, method = c("zscore", "iqr"), threshold = 3) {
method <- match.arg(method)
res <- rep(FALSE, length(x))
if (method == "zscore") {
z <- (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
res <- abs(z) > threshold
} else if (method == "iqr") {
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
res <- x < lower | x > upper
}
res[is.na(x)] <- FALSE  # los NA originales no cuentan como outliers
return(res)
}
# Aplicar a cada variable (columna)
outlier_matrix <- as.data.frame(lapply(X, is_outlier, method = "iqr"))
# ¿Cuántos outliers por variable?
outlier_counts <- colSums(outlier_matrix)
outlier_vars <- names(outlier_counts[outlier_counts > 0])
cat("Variables con outliers detectados:\n")
print(outlier_vars)
# --- Crear resumen por observación ---
outlier_summary <- data.frame(
obs = 1:nrow(X),
n_outlier_vars = rowSums(outlier_matrix),
vars_outlier = apply(outlier_matrix, 1, function(row) {
paste(names(X)[which(row)], collapse = ", ")
})
)
# Mostrar observaciones con al menos un outlier
outlier_summary_nonzero <- subset(outlier_summary, n_outlier_vars > 0)
head(outlier_summary_nonzero, 10)
# --- (Opcional) Reemplazar los outliers por NA en X ---
X_no_outliers <- X
for (v in names(X)) {
X_no_outliers[outlier_matrix[[v]], v] <- NA
}
# Si luego quieres usar la versión sin outliers:
#   -> sustituye X por X_no_outliers en los pasos siguientes
## --- 3) Función de distancia euclídea "pairwise" ajustada por missingness ---
## d_ij = sqrt( sum((xi-xj)^2 over m) * (p / m) ), con m vars observadas en el par
pairwise_dist_row <- function(i, Xs) {
xi <- Xs[i, ]
# Máscara NA por columnas respecto xi (TRUE si xi es no-NA)
mask_i <- !is.na(xi)
d <- rep(NA_real_, n)
for (j in 1:n) {
if (j == i) next
xj <- Xs[j, ]
mask <- mask_i & !is.na(xj)
m <- sum(mask)
if (m == 0) {
d[j] <- NA_real_
} else {
diff2 <- xi[mask] - xj[mask]
d[j] <- sqrt(sum(diff2 * diff2) * (p / m))
}
}
d
}
## --- 4) Obtener el k-NN distance para cada índice objetivo respecto a TODO el dataset ---
get_knn_dist <- function(i, Xs, k = 1) {
d <- pairwise_dist_row(i, Xs)
# Ordenar ignorando NAs y excluyendo la propia observación
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
vec[k]
}
## --- 5) Calcular scores para tus 100 observaciones ---
scores_res <- vapply(idx_targets, function(i) get_knn_dist(i, Xs, k = k), numeric(1))
## --- (Opcional) Si quieres una versión 'avg_k' (media de las k distancias más cercanas) ---
get_knn_avgdist <- function(i, Xs, k = 5) {
d <- pairwise_dist_row(i, Xs)
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
mean(vec[1:k])
}
## --- (Opcional) Normalizaciones monótonas para alinear la "escala" de do_knno ---
## Mantienen el ranking, por si do_knno aplica alguna de estas:
minv <- min(scores_res, na.rm = TRUE); maxv <- max(scores_res, na.rm = TRUE)
resultado_res_knn$score_minmax_0_1 <- (resultado_res_knn$score_knn - minv) / (maxv - minv)
medv <- median(scores_res, na.rm = TRUE); madv <- mad(scores_res, constant = 1, na.rm = TRUE)
resultado_res_knn$score_robust_z <- (resultado_res_knn$score_knn - medv) / madv
## --- Ordenar por mayor sospecha (score más grande) ---
resultado_res_knn <- resultado_res_knn[order(-resultado_res_knn$score_knn), ]
## Ver top
head(resultado_res_knn, 10)
scores_res <- vapply(idx_targets, function(i) get_knn_dist(i, Xs, k = k), numeric(1))
## --- Recalcular matriz estandarizada después de imputar outliers ---
Xs <- as.data.frame(lapply(X_no_outliers, std_col))
Xs <- as.matrix(Xs)
n <- nrow(Xs)  # número de filas actual
## --- Validar índices ---
idx_targets <- idx_targets[idx_targets <= n]
if (length(idx_targets) == 0) {
stop("Ningún índice válido en idx_targets; revisa el contenido de res_knn o el dataset.")
}
## --- 3) Función de distancia euclídea "pairwise" ajustada por missingness ---
## d_ij = sqrt( sum((xi-xj)^2 over m) * (p / m) ), con m vars observadas en el par
pairwise_dist_row <- function(i, Xs) {
xi <- Xs[i, ]
# Máscara NA por columnas respecto xi (TRUE si xi es no-NA)
mask_i <- !is.na(xi)
d <- rep(NA_real_, n)
for (j in 1:n) {
if (j == i) next
xj <- Xs[j, ]
mask <- mask_i & !is.na(xj)
m <- sum(mask)
if (m == 0) {
d[j] <- NA_real_
} else {
diff2 <- xi[mask] - xj[mask]
d[j] <- sqrt(sum(diff2 * diff2) * (p / m))
}
}
d
}
## --- 4) Obtener el k-NN distance para cada índice objetivo respecto a TODO el dataset ---
get_knn_dist <- function(i, Xs, k = 1) {
d <- pairwise_dist_row(i, Xs)
# Ordenar ignorando NAs y excluyendo la propia observación
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
vec[k]
}
## --- 5) Calcular scores para tus 100 observaciones ---
scores_res <- vapply(idx_targets, function(i) get_knn_dist(i, Xs, k = k), numeric(1))
resultado_res_knn <- data.frame(
fila = idx_targets,
score_knn = scores_res
)
## --- (Opcional) Si quieres una versión 'avg_k' (media de las k distancias más cercanas) ---
get_knn_avgdist <- function(i, Xs, k = 5) {
d <- pairwise_dist_row(i, Xs)
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
mean(vec[1:k])
}
# ejemplo: avg_scores_res <- vapply(idx_targets, function(i) get_knn_avgdist(i, Xs, k = 5), numeric(1))
## --- (Opcional) Normalizaciones monótonas para alinear la "escala" de do_knno ---
## Mantienen el ranking, por si do_knno aplica alguna de estas:
minv <- min(scores_res, na.rm = TRUE); maxv <- max(scores_res, na.rm = TRUE)
resultado_res_knn$score_minmax_0_1 <- (resultado_res_knn$score_knn - minv) / (maxv - minv)
medv <- median(scores_res, na.rm = TRUE); madv <- mad(scores_res, constant = 1, na.rm = TRUE)
resultado_res_knn$score_robust_z <- (resultado_res_knn$score_knn - medv) / madv
## --- Ordenar por mayor sospecha (score más grande) ---
resultado_res_knn <- resultado_res_knn[order(-resultado_res_knn$score_knn), ]
## Ver top
head(resultado_res_knn, 10)
## --- Parámetros ---
k <- 1              # usa el mismo k que en do_knno()
idx_targets <- res_knn  # tus 100 índices
## --- 1) Preparar matriz X con variables numéricas ---
X <- datos[, varNum, drop = FALSE]
p <- ncol(X)
## --- 2) Estandarizar por columna ignorando NAs ---
std_col <- function(v) {
mu <- mean(v, na.rm = TRUE)
sdv <- sd(v, na.rm = TRUE)
if (is.na(sdv) || sdv == 0) return((v - mu))   # evita dividir por 0
(v - mu) / sdv
}
Xs <- as.data.frame(lapply(X, std_col))
Xs <- as.matrix(Xs)  # para operaciones más rápidas
n <- nrow(Xs)
## --- 2b) Identificar variables con outliers ---
# Función auxiliar: detecta outliers por variable numérica
detect_outliers <- function(x, method = c("zscore", "iqr"), threshold = 3) {
method <- match.arg(method)
x_noNA <- x[!is.na(x)]
if (method == "zscore") {
z <- (x_noNA - mean(x_noNA)) / sd(x_noNA)
outliers <- which(abs(z) > threshold)
} else if (method == "iqr") {
q1 <- quantile(x_noNA, 0.25)
q3 <- quantile(x_noNA, 0.75)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
outliers <- which(x_noNA < lower | x_noNA > upper)
}
return(length(outliers))
}
# Aplicar a cada variable numérica
outlier_counts <- sapply(X, detect_outliers, method = "iqr")  # puedes cambiar "iqr" por "zscore"
outlier_vars <- names(outlier_counts[outlier_counts > 0])
## Resumen
cat("Variables con outliers detectados:\n")
print(outlier_vars)
cat("\nNúmero de outliers por variable:\n")
print(outlier_counts[outlier_counts > 0])
## (Opcional) Crear un data.frame resumen
resumen_outliers <- data.frame(
variable = names(outlier_counts),
n_outliers = outlier_counts,
prop_outliers = outlier_counts / nrow(X)
)
# Ver las más afectadas
head(resumen_outliers[order(-resumen_outliers$n_outliers), ])
## --- 2c) Identificar y marcar outliers por observación y variable ---
# Función que devuelve un vector lógico (TRUE si es outlier)
is_outlier <- function(x, method = c("zscore", "iqr"), threshold = 3) {
method <- match.arg(method)
res <- rep(FALSE, length(x))
if (method == "zscore") {
z <- (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
res <- abs(z) > threshold
} else if (method == "iqr") {
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
res <- x < lower | x > upper
}
res[is.na(x)] <- FALSE  # los NA originales no cuentan como outliers
return(res)
}
# Aplicar a cada variable (columna)
outlier_matrix <- as.data.frame(lapply(X, is_outlier, method = "iqr"))
# ¿Cuántos outliers por variable?
outlier_counts <- colSums(outlier_matrix)
outlier_vars <- names(outlier_counts[outlier_counts > 0])
cat("Variables con outliers detectados:\n")
print(outlier_vars)
# --- Crear resumen por observación ---
outlier_summary <- data.frame(
obs = 1:nrow(X),
n_outlier_vars = rowSums(outlier_matrix),
vars_outlier = apply(outlier_matrix, 1, function(row) {
paste(names(X)[which(row)], collapse = ", ")
})
)
# Mostrar observaciones con al menos un outlier
outlier_summary_nonzero <- subset(outlier_summary, n_outlier_vars > 0)
head(outlier_summary_nonzero, 10)
# --- (Opcional) Reemplazar los outliers por NA en X ---
X_no_outliers <- X
for (v in names(X)) {
X_no_outliers[outlier_matrix[[v]], v] <- NA
}
# Si luego quieres usar la versión sin outliers:
#   -> sustituye X por X_no_outliers en los pasos siguientes
## --- Recalcular matriz estandarizada después de imputar outliers ---
Xs <- as.data.frame(lapply(X_no_outliers, std_col))
Xs <- as.matrix(Xs)
n <- nrow(Xs)  # número de filas actual
## --- Validar índices ---
idx_targets <- idx_targets[idx_targets <= n]
if (length(idx_targets) == 0) {
stop("Ningún índice válido en idx_targets; revisa el contenido de res_knn o el dataset.")
}
## --- 3) Función de distancia euclídea "pairwise" ajustada por missingness ---
## d_ij = sqrt( sum((xi-xj)^2 over m) * (p / m) ), con m vars observadas en el par
pairwise_dist_row <- function(i, Xs) {
xi <- Xs[i, ]
# Máscara NA por columnas respecto xi (TRUE si xi es no-NA)
mask_i <- !is.na(xi)
d <- rep(NA_real_, n)
for (j in 1:n) {
if (j == i) next
xj <- Xs[j, ]
mask <- mask_i & !is.na(xj)
m <- sum(mask)
if (m == 0) {
d[j] <- NA_real_
} else {
diff2 <- xi[mask] - xj[mask]
d[j] <- sqrt(sum(diff2 * diff2) * (p / m))
}
}
d
}
## --- 4) Obtener el k-NN distance para cada índice objetivo respecto a TODO el dataset ---
get_knn_dist <- function(i, Xs, k = 1) {
d <- pairwise_dist_row(i, Xs)
# Ordenar ignorando NAs y excluyendo la propia observación
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
vec[k]
}
## --- 5) Calcular scores para tus 100 observaciones ---
scores_res <- vapply(idx_targets, function(i) get_knn_dist(i, Xs, k = k), numeric(1))
resultado_res_knn <- data.frame(
fila = idx_targets,
score_knn = scores_res
)
## --- (Opcional) Si quieres una versión 'avg_k' (media de las k distancias más cercanas) ---
get_knn_avgdist <- function(i, Xs, k = 5) {
d <- pairwise_dist_row(i, Xs)
vec <- sort(d[!is.na(d)], partial = k)
if (length(vec) < k) return(NA_real_)
mean(vec[1:k])
}
# ejemplo: avg_scores_res <- vapply(idx_targets, function(i) get_knn_avgdist(i, Xs, k = 5), numeric(1))
## --- (Opcional) Normalizaciones monótonas para alinear la "escala" de do_knno ---
## Mantienen el ranking, por si do_knno aplica alguna de estas:
minv <- min(scores_res, na.rm = TRUE); maxv <- max(scores_res, na.rm = TRUE)
resultado_res_knn$score_minmax_0_1 <- (resultado_res_knn$score_knn - minv) / (maxv - minv)
medv <- median(scores_res, na.rm = TRUE); madv <- mad(scores_res, constant = 1, na.rm = TRUE)
resultado_res_knn$score_robust_z <- (resultado_res_knn$score_knn - medv) / madv
## --- Ordenar por mayor sospecha (score más grande) ---
resultado_res_knn <- resultado_res_knn[order(-resultado_res_knn$score_knn), ]
## Ver top
head(resultado_res_knn, 10)
